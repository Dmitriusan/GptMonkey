{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load OpenAI API key from .env file https://stackoverflow.com/a/76928988\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from model.completion import EvaluatedCompletion\n",
    "\n",
    "load_dotenv()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:32:16.421691498Z",
     "start_time": "2023-10-04T14:32:16.421266096Z"
    }
   },
   "id": "b30b71f2cd35359"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "import prompt_generator\n",
    "from model.conversation import Conversation\n",
    "from model.conversation_step import ConversationStep\n",
    "from model.context import Context\n",
    "from model.prompt import Prompt\n",
    "\n",
    "import prompt_generator\n",
    "\n",
    "from openai_util import get_completion, set_api_key, pretty_print_conversation\n",
    "set_api_key()\n",
    "\n",
    "app_dir = os.path.abspath(prompt_generator.__file__)\n",
    "os.chdir(os.path.join(os.path.dirname(app_dir), \"..\")) # To make Jinja template paths correct \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:32:16.641903124Z",
     "start_time": "2023-10-04T14:32:16.421462902Z"
    }
   },
   "id": "33eedff61e57a5d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31msystem: You are an expert programmer. Decompose the task given by user to an exhaustive list of small steps (simple tasks). Each\n",
      " step will then be completed as a single prompt by gpt-3.5-turbo model (that is  working with a project through `VIM` editor). Executing all steps in specified order should result in\n",
      "completion of the entire user task.\n",
      "\u001B[0m\n",
      "\u001B[32muser: The technology stack is: Python 3, Jinja2\n",
      "Task for programmer: externalize all hardcoded strings that are visible to application user\n",
      "\n",
      "\u001B[0m\n",
      "\u001B[33mfunctions: [{'description': 'call if you need to check content of existing project files '\n",
      "                 'to understand user task',\n",
      "  'name': 'preview_project_files',\n",
      "  'parameters': {'properties': {'path_within_project': {'description': 'The '\n",
      "                                                                       'city '\n",
      "                                                                       'and '\n",
      "                                                                       'state, '\n",
      "                                                                       'e.g. '\n",
      "                                                                       'San '\n",
      "                                                                       'Francisco, '\n",
      "                                                                       'CA',\n",
      "                                                        'type': 'string'}},\n",
      "                 'required': ['path_within_project'],\n",
      "                 'type': 'object'}},\n",
      " {'description': 'Store steps of decomposed task',\n",
      "  'name': 'store_task_decomposition',\n",
      "  'parameters': {'properties': {'steps': {'description': 'List of steps '\n",
      "                                                         'descriptions',\n",
      "                                          'items': {'type': 'string'},\n",
      "                                          'type': 'array'}},\n",
      "                 'required': ['steps'],\n",
      "                 'type': 'object'}}]\n",
      "\u001B[0m\n",
      "\u001B[33mfunction_call: auto\n",
      "\u001B[0m\n",
      "--------------------------------\n",
      "Completion: {\n",
      "  \"id\": \"chatcmpl-85xEFxf9wOr3Xw6ATjJ7hPAYqjA9p\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1696430007,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"store_task_decomposition\",\n",
      "          \"arguments\": \"{\\n  \\\"steps\\\": [\\n    \\\"Identify all hardcoded strings in the application\\\",\\n    \\\"Determine which strings are visible to the application user\\\",\\n    \\\"For each visible string, extract it from the code\\\",\\n    \\\"Create a separate file to store the extracted strings\\\",\\n    \\\"Replace the extracted strings in the code with references to the new file\\\",\\n    \\\"Test the application to ensure the functionality is not affected by the changes\\\"\\n  ]\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 211,\n",
      "    \"completion_tokens\": 98,\n",
      "    \"total_tokens\": 309\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt_file_path = \"user_codechange_prompt.txt\"\n",
    "with open(prompt_file_path, \"r\") as prompt_file:\n",
    "  high_level_prompt = prompt_file.read()\n",
    "context = Context(os.getcwd(), prompt_file_path, high_level_prompt)\n",
    "\n",
    "prompt = prompt_generator.decompose_prompt(context)\n",
    "convStep = ConversationStep(prompt)\n",
    "context.conversation.append(convStep)\n",
    "\n",
    "pretty_print_conversation(prompt.to_messages(), prompt.functions, prompt.function_call)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "completion_response = get_completion(context.conversation)\n",
    "\n",
    "context.conversation.history[-1].completion = EvaluatedCompletion(completion_response)\n",
    "\n",
    "pretty_print_conversation(context.conversation.to_messages())\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-04T14:33:27.123367137Z"
    }
   },
   "id": "2525f417792545d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:32:21.054609390Z",
     "start_time": "2023-10-04T14:32:21.051911579Z"
    }
   },
   "id": "ee70995223268c6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "test `ff`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a17d8e51275add38"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
